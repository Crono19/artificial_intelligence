{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d57c1736-e35f-48ea-82e3-7c3e3ccfe2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pablo/Documents/GitHub/artificial_intelligence/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/enalis/tomatoes-dataset?dataset_version_number=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93.7M/93.7M [00:02<00:00, 38.9MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/pablo/.cache/kagglehub/datasets/enalis/tomatoes-dataset/versions/4\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"enalis/tomatoes-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97d05206-ce3a-4318-b7a9-8a867cf2fd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenido de la carpeta 'val':\n",
      "Unripe\n",
      "Old\n",
      "Damaged\n",
      "Ripe\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "val_path = r\"/Users/pablo/.cache/kagglehub/datasets/enalis/tomatoes-dataset/versions/4/content/ieee-mbl-cls/val\"\n",
    "\n",
    "# Listar los archivos o carpetas dentro del directorio\n",
    "contenido = os.listdir(val_path)\n",
    "\n",
    "print(\"Contenido de la carpeta 'val':\")\n",
    "for item in contenido:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f8ad2ed-e43c-4a1b-8b88-646a1c2e1022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_dir = os.path.join(path, 'train')\n",
    "val_dir = os.path.join(path, 'validation')\n",
    "\n",
    "# o si no están divididas en train/validation, puedes usar una sola carpeta y dividir tú mismo con ImageDataGenerator con validation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a08bfdf7-0fd3-4eef-9643-7e81729ead09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pablo/.cache/kagglehub/datasets/enalis/tomatoes-dataset/versions/4/train\n",
      "/Users/pablo/.cache/kagglehub/datasets/enalis/tomatoes-dataset/versions/4/validation\n"
     ]
    }
   ],
   "source": [
    "print(train_dir)\n",
    "print(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d4361ef-777c-4e95-a7d7-ee7ea4963f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6500 images belonging to 4 classes.\n",
      "Found 724 images belonging to 4 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pablo/Documents/GitHub/artificial_intelligence/.venv/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/pablo/Documents/GitHub/artificial_intelligence/.venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 108ms/step - accuracy: 0.6289 - loss: 0.8904 - val_accuracy: 0.7735 - val_loss: 0.5608\n",
      "Epoch 2/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 107ms/step - accuracy: 0.8021 - loss: 0.4845 - val_accuracy: 0.8605 - val_loss: 0.3717\n",
      "Epoch 3/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 110ms/step - accuracy: 0.8466 - loss: 0.3783 - val_accuracy: 0.8011 - val_loss: 0.5693\n",
      "Epoch 4/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 110ms/step - accuracy: 0.8537 - loss: 0.3788 - val_accuracy: 0.8798 - val_loss: 0.3080\n",
      "Epoch 5/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - accuracy: 0.8833 - loss: 0.3086 - val_accuracy: 0.8536 - val_loss: 0.3572\n",
      "Epoch 6/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - accuracy: 0.8687 - loss: 0.3378 - val_accuracy: 0.8840 - val_loss: 0.2997\n",
      "Epoch 7/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8768 - loss: 0.3082 - val_accuracy: 0.8149 - val_loss: 0.4186\n",
      "Epoch 8/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - accuracy: 0.8744 - loss: 0.3249 - val_accuracy: 0.8702 - val_loss: 0.3335\n",
      "Epoch 9/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 572ms/step - accuracy: 0.8839 - loss: 0.3076 - val_accuracy: 0.9088 - val_loss: 0.2600\n",
      "Epoch 10/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 113ms/step - accuracy: 0.9022 - loss: 0.2588 - val_accuracy: 0.8936 - val_loss: 0.2607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Parámetros\n",
    "ancho, alto = 150, 150\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Rutas a los directorios\n",
    "train_dir = val_dir = '/Users/pablo/.cache/kagglehub/datasets/enalis/tomatoes-dataset/versions/4/content/ieee-mbl-cls/train'\n",
    "val_dir = val_dir = '/Users/pablo/.cache/kagglehub/datasets/enalis/tomatoes-dataset/versions/4/content/ieee-mbl-cls/val'\n",
    "\n",
    "# Aumento de datos para mejorar el entrenamiento\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Carga de imágenes desde carpetas\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(alto, ancho),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(alto, ancho),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Definición del modelo CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(alto, ancho, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(4, activation='softmax')  # 3 clases: verde, pinton, maduro\n",
    "])\n",
    "\n",
    "# Compilación del modelo\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model.save('modelo_tomates.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5343d85b-b1bc-4255-a262-ebe18c681bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "La imagen es un tomate pinton con una confianza del 80.65%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model = load_model('modelo_tomates.h5')\n",
    "\n",
    "# Lista de clases en el mismo orden que se usó en el entrenamiento\n",
    "clases = ['verde', 'pinton', 'maduro']\n",
    "\n",
    "# Ruta a la imagen que quieres clasificar\n",
    "img_path = 'images/tomate-pinton-1.jpg'  # por ejemplo: 'test_tomate.jpg'\n",
    "\n",
    "# Preprocesar la imagen\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "img_array = image.img_to_array(img) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Convertir a batch\n",
    "\n",
    "# Realizar la predicción\n",
    "prediccion = model.predict(img_array)\n",
    "indice = np.argmax(prediccion)\n",
    "confianza = np.max(prediccion)\n",
    "\n",
    "# Mostrar resultado\n",
    "print(f\"La imagen es un tomate {clases[indice]} con una confianza del {confianza:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a42b22d-dfb2-4d22-80dd-492445960067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
